{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f796fa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "e06d450bcab24419b1bcb23e21ab91e5",
            "aaaf303e021344cc82f4d2850f2eca86",
            "baa17d6c8c8346f98f7f163bdade3518",
            "7d47031a8f9042ff856f611f2686428d",
            "a948f933e48240888513907543eb59a4",
            "7ddbb5bd3040450f88f216b058c2e7cc",
            "bc493bf2967c484797ce2a6e0a2516ca",
            "49c4086a939742a3ad3f5aaa495a4615",
            "8a4793fad18f4d98b11477eadab9714c",
            "f4b6897d893c4629ad63c5eb76bfec69",
            "204c547c0b4a47e480ccec1b904e1ecf"
          ]
        },
        "id": "34f796fa",
        "outputId": "c0c86208-ff7d-4544-c9f4-be138a390fda"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "from torch.utils.data import default_collate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YXhkwMgm0tc0",
      "metadata": {
        "id": "YXhkwMgm0tc0"
      },
      "outputs": [],
      "source": [
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "loTr3R6u0tfn",
      "metadata": {
        "id": "loTr3R6u0tfn"
      },
      "outputs": [],
      "source": [
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, cache_dir=\"/media/tamal/New_HardDrive/Machine Learning, AI/Aaladin AI/model and tokenizers\")\n",
        "# Add padding\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cYcDRrJn0tiw",
      "metadata": {
        "id": "cYcDRrJn0tiw"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    cache_dir=\"/media/tamal/New_HardDrive/Machine Learning, AI/Aaladin AI/model and tokenizers\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ynY_tyo61HXa",
      "metadata": {
        "id": "ynY_tyo61HXa"
      },
      "source": [
        "### LoRA config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zJNyiEGk1UQC",
      "metadata": {
        "id": "zJNyiEGk1UQC"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"up_proj\", \"down_proj\", \"gate_proj\"],\n",
        ")\n",
        "model = get_peft_model(base_model, lora_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QoSxL-Oa1as1",
      "metadata": {
        "id": "QoSxL-Oa1as1"
      },
      "outputs": [],
      "source": [
        "# Load Dataset\n",
        "ds = load_dataset(\"databricks/databricks-dolly-15k\", split=\"train[:10000]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25afec56",
      "metadata": {},
      "outputs": [],
      "source": [
        "ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82b81cbd",
      "metadata": {},
      "outputs": [],
      "source": [
        "ds['instruction']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90354d1d",
      "metadata": {},
      "outputs": [],
      "source": [
        "ds['response']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "AoyZRZaI1qIR",
      "metadata": {
        "id": "AoyZRZaI1qIR"
      },
      "source": [
        "### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kPliSaHE1gdg",
      "metadata": {
        "id": "kPliSaHE1gdg"
      },
      "outputs": [],
      "source": [
        "# Build chat using the model's template\n",
        "def build_messages(instruction, context, response):\n",
        "    # instruction (user ask), context (optional), response (assistant)\n",
        "    user_text = instruction if instruction else \"\"\n",
        "    if context and len(context.strip()) > 0:\n",
        "        user_text = f\"{user_text}\\n\\nContext:\\n{context}\".strip()\n",
        "\n",
        "    # messages list in HF chat format\n",
        "    msgs = [\n",
        "        {\"role\": \"user\", \"content\": user_text},\n",
        "        {\"role\": \"assistant\", \"content\": response if response else \"\"},\n",
        "    ]\n",
        "    return msgs\n",
        "\n",
        "\n",
        "\n",
        "#  Preprocess: create prompt-only and prompt+response encodings, then mask labels\n",
        "max_len = 1024\n",
        "\n",
        "def preprocess_batch(batch):\n",
        "    prompts_text = []        # up to assistant start (no answer text)\n",
        "    full_text = []           # prompt + assistant response\n",
        "\n",
        "    for instr, ctx, resp in zip(batch[\"instruction\"], batch[\"context\"], batch[\"response\"]):\n",
        "        msgs = build_messages(instr, ctx, resp)\n",
        "\n",
        "        # prompt-only text (generation prompt = True adds assistant header)\n",
        "        prompt_only = tokenizer.apply_chat_template(\n",
        "            msgs[:1],  # only the user message\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=True,  # adds the assistant prefix the model expects\n",
        "        )\n",
        "        # full text with assistant message included\n",
        "        full = tokenizer.apply_chat_template(\n",
        "            msgs,\n",
        "            tokenize=False,\n",
        "            add_generation_prompt=False,\n",
        "        )\n",
        "\n",
        "        prompts_text.append(prompt_only)\n",
        "        full_text.append(full)\n",
        "\n",
        "    # Tokenize both\n",
        "    tok_prompt = tokenizer(\n",
        "        prompts_text,\n",
        "        max_length=max_len,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        add_special_tokens=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "    tok_full = tokenizer(\n",
        "        full_text,\n",
        "        max_length=max_len,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        add_special_tokens=True,\n",
        "        return_tensors=\"pt\",\n",
        "    )\n",
        "\n",
        "    input_ids = tok_full[\"input_ids\"]\n",
        "    attention_mask = tok_full[\"attention_mask\"]\n",
        "\n",
        "    # Labels start as a copy of input_ids\n",
        "    labels = input_ids.clone()\n",
        "\n",
        "    # Mask everything that belongs to the prompt-only prefix\n",
        "    # For each sample, find the prompt length by re-tokenizing prompt-only\n",
        "    prompt_len = (tok_prompt[\"attention_mask\"].sum(dim=1)).tolist()  # length per example\n",
        "\n",
        "    for i, p_len in enumerate(prompt_len):\n",
        "        # mask prompt tokens\n",
        "        labels[i, :p_len] = -100\n",
        "        # also mask padding positions anywhere attention_mask == 0\n",
        "        labels[i, attention_mask[i] == 0] = -100\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": input_ids,\n",
        "        \"attention_mask\": attention_mask,\n",
        "        \"labels\": labels,\n",
        "    }\n",
        "\n",
        "proc = ds.map(\n",
        "    preprocess_batch,\n",
        "    batched=True,\n",
        "    remove_columns=ds.column_names,\n",
        "    desc=\"Formatting with chat template + masking\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "t22RHx663t2x",
      "metadata": {
        "id": "t22RHx663t2x"
      },
      "outputs": [],
      "source": [
        "# Data collator — just pad; labels already masked\n",
        "class LMDataCollator:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, features):\n",
        "        # Convert lists to tensors before stacking\n",
        "        for f in features:\n",
        "            for k, v in f.items():\n",
        "                if not isinstance(v, torch.Tensor):\n",
        "                    f[k] = torch.tensor(v, dtype=torch.long)\n",
        "        return default_collate(features)\n",
        "\n",
        "collator = LMDataCollator(tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "IPT6wwb237Ga",
      "metadata": {
        "id": "IPT6wwb237Ga"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-UR7wjG30rVK",
      "metadata": {
        "id": "-UR7wjG30rVK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Training\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"./deepseek-lora-fixed\",\n",
        "    per_device_train_batch_size=1,          # raise if VRAM allows\n",
        "    gradient_accumulation_steps=4,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=50,\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=1,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=proc,\n",
        "    data_collator=collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hO5bcI-6uDnw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "hO5bcI-6uDnw",
        "outputId": "79e3de2a-0e46-43b9-e65d-2f55f5b43c7c"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UYS3KPBqz2sE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYS3KPBqz2sE",
        "outputId": "c58cb0ec-9a6f-4434-ba36-7efdbb32a25f"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(\"./deepseek-lora-fixed\")\n",
        "tokenizer.save_pretrained(\"./deepseek-lora-fixed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bdkD9jKzE6B",
      "metadata": {
        "id": "1bdkD9jKzE6B"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kVhBv403zDe_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVhBv403zDe_",
        "outputId": "9a8484d3-09c7-401d-fef7-92f19a7b7ee6"
      },
      "outputs": [],
      "source": [
        "base = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name, torch_dtype=torch.float16, device_map=\"auto\"\n",
        ")\n",
        "ft = PeftModel.from_pretrained(base, \"./deepseek-lora-fixed\")\n",
        "ft = ft.merge_and_unload()  # merge LoRA into base weights\n",
        "ft.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F_ZeoEu8zIUu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_ZeoEu8zIUu",
        "outputId": "333cf410-f603-47fa-8679-1a722200ab04"
      },
      "outputs": [],
      "source": [
        "def chat_infer(user_text, max_new_tokens=128):\n",
        "    messages = [{\"role\": \"user\", \"content\": user_text}]\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages, tokenize=True, add_generation_prompt=True, return_tensors=\"pt\"\n",
        "    ).to(ft.device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        out = ft.generate(\n",
        "            input_ids=prompt,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            temperature=0.8,\n",
        "            top_p=0.9,\n",
        "            do_sample=True,\n",
        "            repetition_penalty=1.15,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "        )\n",
        "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
        "    return text\n",
        "\n",
        "print(\"\\n--- Inference sample ---\")\n",
        "print(chat_infer(\"When did Virgin Australia start operating?\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tamal",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "204c547c0b4a47e480ccec1b904e1ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49c4086a939742a3ad3f5aaa495a4615": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d47031a8f9042ff856f611f2686428d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4b6897d893c4629ad63c5eb76bfec69",
            "placeholder": "​",
            "style": "IPY_MODEL_204c547c0b4a47e480ccec1b904e1ecf",
            "value": " 2000/2000 [00:08&lt;00:00, 234.62 examples/s]"
          }
        },
        "7ddbb5bd3040450f88f216b058c2e7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4793fad18f4d98b11477eadab9714c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a948f933e48240888513907543eb59a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaaf303e021344cc82f4d2850f2eca86": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ddbb5bd3040450f88f216b058c2e7cc",
            "placeholder": "​",
            "style": "IPY_MODEL_bc493bf2967c484797ce2a6e0a2516ca",
            "value": "Formatting with chat template + masking: 100%"
          }
        },
        "baa17d6c8c8346f98f7f163bdade3518": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49c4086a939742a3ad3f5aaa495a4615",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a4793fad18f4d98b11477eadab9714c",
            "value": 2000
          }
        },
        "bc493bf2967c484797ce2a6e0a2516ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e06d450bcab24419b1bcb23e21ab91e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aaaf303e021344cc82f4d2850f2eca86",
              "IPY_MODEL_baa17d6c8c8346f98f7f163bdade3518",
              "IPY_MODEL_7d47031a8f9042ff856f611f2686428d"
            ],
            "layout": "IPY_MODEL_a948f933e48240888513907543eb59a4"
          }
        },
        "f4b6897d893c4629ad63c5eb76bfec69": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
